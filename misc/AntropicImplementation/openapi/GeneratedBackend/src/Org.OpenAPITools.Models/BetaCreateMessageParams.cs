/*
 * Anthropic API
 *
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 0.0.0
 * 
 * Generated by: https://openapi-generator.tech
 */

using System;
using System.Linq;
using System.Text;
using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Runtime.Serialization;
using System.Text.Json;
using Org.OpenAPITools.Converters;

namespace Org.OpenAPITools.Models
{ 
    /// <summary>
    /// 
    /// </summary>
    [DataContract]
    public partial class BetaCreateMessageParams 
    {
        /// <summary>
        /// Gets or Sets Model
        /// </summary>
        [Required]
        [DataMember(Name="model", EmitDefaultValue=false)]
        public Model Model { get; set; }

        /// <summary>
        /// Input messages.  Our models are trained to operate on alternating &#x60;user&#x60; and &#x60;assistant&#x60; conversational turns. When creating a new &#x60;Message&#x60;, you specify the prior conversational turns with the &#x60;messages&#x60; parameter, and the model then generates the next &#x60;Message&#x60; in the conversation. Consecutive &#x60;user&#x60; or &#x60;assistant&#x60; turns in your request will be combined into a single turn.  Each input message must be an object with a &#x60;role&#x60; and &#x60;content&#x60;. You can specify a single &#x60;user&#x60;-role message, or you can include multiple &#x60;user&#x60; and &#x60;assistant&#x60; messages.  If the final message uses the &#x60;assistant&#x60; role, the response content will continue immediately from the content in that message. This can be used to constrain part of the model&#39;s response.  Example with a single &#x60;user&#x60; message:  &#x60;&#x60;&#x60;json [{\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello, Claude\&quot;}] &#x60;&#x60;&#x60;  Example with multiple conversational turns:  &#x60;&#x60;&#x60;json [   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello there.\&quot;},   {\&quot;role\&quot;: \&quot;assistant\&quot;, \&quot;content\&quot;: \&quot;Hi, I&#39;m Claude. How can I help you?\&quot;},   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Can you explain LLMs in plain English?\&quot;}, ] &#x60;&#x60;&#x60;  Example with a partially-filled response from Claude:  &#x60;&#x60;&#x60;json [   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;What&#39;s the Greek name for Sun? (A) Sol (B) Helios (C) Sun\&quot;},   {\&quot;role\&quot;: \&quot;assistant\&quot;, \&quot;content\&quot;: \&quot;The best answer is (\&quot;}, ] &#x60;&#x60;&#x60;  Each input message &#x60;content&#x60; may be either a single &#x60;string&#x60; or an array of content blocks, where each block has a specific &#x60;type&#x60;. Using a &#x60;string&#x60; for &#x60;content&#x60; is shorthand for an array of one content block of type &#x60;\&quot;text\&quot;&#x60;. The following input messages are equivalent:  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello, Claude\&quot;} &#x60;&#x60;&#x60;  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: [{\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;Hello, Claude\&quot;}]} &#x60;&#x60;&#x60;  Starting with Claude 3 models, you can also send image content blocks:  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: [   {     \&quot;type\&quot;: \&quot;image\&quot;,     \&quot;source\&quot;: {       \&quot;type\&quot;: \&quot;base64\&quot;,       \&quot;media_type\&quot;: \&quot;image/jpeg\&quot;,       \&quot;data\&quot;: \&quot;/9j/4AAQSkZJRg...\&quot;,     }   },   {\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;What is in this image?\&quot;} ]} &#x60;&#x60;&#x60;  We currently support the &#x60;base64&#x60; source type for images, and the &#x60;image/jpeg&#x60;, &#x60;image/png&#x60;, &#x60;image/gif&#x60;, and &#x60;image/webp&#x60; media types.  See [examples](https://docs.anthropic.com/en/api/messages-examples#vision) for more input examples.  Note that if you want to include a [system prompt](https://docs.anthropic.com/en/docs/system-prompts), you can use the top-level &#x60;system&#x60; parameter — there is no &#x60;\&quot;system\&quot;&#x60; role for input messages in the Messages API.
        /// </summary>
        /// <value>Input messages.  Our models are trained to operate on alternating &#x60;user&#x60; and &#x60;assistant&#x60; conversational turns. When creating a new &#x60;Message&#x60;, you specify the prior conversational turns with the &#x60;messages&#x60; parameter, and the model then generates the next &#x60;Message&#x60; in the conversation. Consecutive &#x60;user&#x60; or &#x60;assistant&#x60; turns in your request will be combined into a single turn.  Each input message must be an object with a &#x60;role&#x60; and &#x60;content&#x60;. You can specify a single &#x60;user&#x60;-role message, or you can include multiple &#x60;user&#x60; and &#x60;assistant&#x60; messages.  If the final message uses the &#x60;assistant&#x60; role, the response content will continue immediately from the content in that message. This can be used to constrain part of the model&#39;s response.  Example with a single &#x60;user&#x60; message:  &#x60;&#x60;&#x60;json [{\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello, Claude\&quot;}] &#x60;&#x60;&#x60;  Example with multiple conversational turns:  &#x60;&#x60;&#x60;json [   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello there.\&quot;},   {\&quot;role\&quot;: \&quot;assistant\&quot;, \&quot;content\&quot;: \&quot;Hi, I&#39;m Claude. How can I help you?\&quot;},   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Can you explain LLMs in plain English?\&quot;}, ] &#x60;&#x60;&#x60;  Example with a partially-filled response from Claude:  &#x60;&#x60;&#x60;json [   {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;What&#39;s the Greek name for Sun? (A) Sol (B) Helios (C) Sun\&quot;},   {\&quot;role\&quot;: \&quot;assistant\&quot;, \&quot;content\&quot;: \&quot;The best answer is (\&quot;}, ] &#x60;&#x60;&#x60;  Each input message &#x60;content&#x60; may be either a single &#x60;string&#x60; or an array of content blocks, where each block has a specific &#x60;type&#x60;. Using a &#x60;string&#x60; for &#x60;content&#x60; is shorthand for an array of one content block of type &#x60;\&quot;text\&quot;&#x60;. The following input messages are equivalent:  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: \&quot;Hello, Claude\&quot;} &#x60;&#x60;&#x60;  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: [{\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;Hello, Claude\&quot;}]} &#x60;&#x60;&#x60;  Starting with Claude 3 models, you can also send image content blocks:  &#x60;&#x60;&#x60;json {\&quot;role\&quot;: \&quot;user\&quot;, \&quot;content\&quot;: [   {     \&quot;type\&quot;: \&quot;image\&quot;,     \&quot;source\&quot;: {       \&quot;type\&quot;: \&quot;base64\&quot;,       \&quot;media_type\&quot;: \&quot;image/jpeg\&quot;,       \&quot;data\&quot;: \&quot;/9j/4AAQSkZJRg...\&quot;,     }   },   {\&quot;type\&quot;: \&quot;text\&quot;, \&quot;text\&quot;: \&quot;What is in this image?\&quot;} ]} &#x60;&#x60;&#x60;  We currently support the &#x60;base64&#x60; source type for images, and the &#x60;image/jpeg&#x60;, &#x60;image/png&#x60;, &#x60;image/gif&#x60;, and &#x60;image/webp&#x60; media types.  See [examples](https://docs.anthropic.com/en/api/messages-examples#vision) for more input examples.  Note that if you want to include a [system prompt](https://docs.anthropic.com/en/docs/system-prompts), you can use the top-level &#x60;system&#x60; parameter — there is no &#x60;\&quot;system\&quot;&#x60; role for input messages in the Messages API.</value>
        [Required]
        [DataMember(Name="messages", EmitDefaultValue=false)]
        public List<BetaInputMessage> Messages { get; set; }

        /// <summary>
        /// The maximum number of tokens to generate before stopping.  Note that our models may stop _before_ reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate.  Different models have different maximum values for this parameter.  See [models](https://docs.anthropic.com/en/docs/models-overview) for details.
        /// </summary>
        /// <value>The maximum number of tokens to generate before stopping.  Note that our models may stop _before_ reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate.  Different models have different maximum values for this parameter.  See [models](https://docs.anthropic.com/en/docs/models-overview) for details.</value>
        [Required]
        [DataMember(Name="max_tokens", EmitDefaultValue=true)]
        public int MaxTokens { get; set; }

        /// <summary>
        /// An object describing metadata about the request.
        /// </summary>
        /// <value>An object describing metadata about the request.</value>
        [DataMember(Name="metadata", EmitDefaultValue=false)]
        public BetaMetadata? Metadata { get; set; }

        /// <summary>
        /// Custom text sequences that will cause the model to stop generating.  Our models will normally stop when they have naturally completed their turn, which will result in a response &#x60;stop_reason&#x60; of &#x60;\&quot;end_turn\&quot;&#x60;.  If you want the model to stop generating when it encounters custom strings of text, you can use the &#x60;stop_sequences&#x60; parameter. If the model encounters one of the custom sequences, the response &#x60;stop_reason&#x60; value will be &#x60;\&quot;stop_sequence\&quot;&#x60; and the response &#x60;stop_sequence&#x60; value will contain the matched stop sequence.
        /// </summary>
        /// <value>Custom text sequences that will cause the model to stop generating.  Our models will normally stop when they have naturally completed their turn, which will result in a response &#x60;stop_reason&#x60; of &#x60;\&quot;end_turn\&quot;&#x60;.  If you want the model to stop generating when it encounters custom strings of text, you can use the &#x60;stop_sequences&#x60; parameter. If the model encounters one of the custom sequences, the response &#x60;stop_reason&#x60; value will be &#x60;\&quot;stop_sequence\&quot;&#x60; and the response &#x60;stop_sequence&#x60; value will contain the matched stop sequence.</value>
        [DataMember(Name="stop_sequences", EmitDefaultValue=false)]
        public List<string> StopSequences { get; set; }

        /// <summary>
        /// Whether to incrementally stream the response using server-sent events.  See [streaming](https://docs.anthropic.com/en/api/messages-streaming) for details.
        /// </summary>
        /// <value>Whether to incrementally stream the response using server-sent events.  See [streaming](https://docs.anthropic.com/en/api/messages-streaming) for details.</value>
        [DataMember(Name="stream", EmitDefaultValue=true)]
        public bool? Stream { get; set; }

        /// <summary>
        /// Gets or Sets System
        /// </summary>
        [DataMember(Name="system", EmitDefaultValue=false)]
        public System1? System { get; set; }

        /// <summary>
        /// Amount of randomness injected into the response.  Defaults to &#x60;1.0&#x60;. Ranges from &#x60;0.0&#x60; to &#x60;1.0&#x60;. Use &#x60;temperature&#x60; closer to &#x60;0.0&#x60; for analytical / multiple choice, and closer to &#x60;1.0&#x60; for creative and generative tasks.  Note that even with &#x60;temperature&#x60; of &#x60;0.0&#x60;, the results will not be fully deterministic.
        /// </summary>
        /// <value>Amount of randomness injected into the response.  Defaults to &#x60;1.0&#x60;. Ranges from &#x60;0.0&#x60; to &#x60;1.0&#x60;. Use &#x60;temperature&#x60; closer to &#x60;0.0&#x60; for analytical / multiple choice, and closer to &#x60;1.0&#x60; for creative and generative tasks.  Note that even with &#x60;temperature&#x60; of &#x60;0.0&#x60;, the results will not be fully deterministic.</value>
        [Range(0, 1)]
        [DataMember(Name="temperature", EmitDefaultValue=true)]
        public decimal? Temperature { get; set; }

        /// <summary>
        /// Gets or Sets ToolChoice
        /// </summary>
        [DataMember(Name="tool_choice", EmitDefaultValue=false)]
        public BetaToolChoice? ToolChoice { get; set; }

        /// <summary>
        /// Definitions of tools that the model may use.  If you include &#x60;tools&#x60; in your API request, the model may return &#x60;tool_use&#x60; content blocks that represent the model&#39;s use of those tools. You can then run those tools using the tool input generated by the model and then optionally return results back to the model using &#x60;tool_result&#x60; content blocks.  Each tool definition includes:  * &#x60;name&#x60;: Name of the tool. * &#x60;description&#x60;: Optional, but strongly-recommended description of the tool. * &#x60;input_schema&#x60;: [JSON schema](https://json-schema.org/) for the tool &#x60;input&#x60; shape that the model will produce in &#x60;tool_use&#x60; output content blocks.  For example, if you defined &#x60;tools&#x60; as:  &#x60;&#x60;&#x60;json [   {     \&quot;name\&quot;: \&quot;get_stock_price\&quot;,     \&quot;description\&quot;: \&quot;Get the current stock price for a given ticker symbol.\&quot;,     \&quot;input_schema\&quot;: {       \&quot;type\&quot;: \&quot;object\&quot;,       \&quot;properties\&quot;: {         \&quot;ticker\&quot;: {           \&quot;type\&quot;: \&quot;string\&quot;,           \&quot;description\&quot;: \&quot;The stock ticker symbol, e.g. AAPL for Apple Inc.\&quot;         }       },       \&quot;required\&quot;: [\&quot;ticker\&quot;]     }   } ] &#x60;&#x60;&#x60;  And then asked the model \&quot;What&#39;s the S&amp;P 500 at today?\&quot;, the model might produce &#x60;tool_use&#x60; content blocks in the response like this:  &#x60;&#x60;&#x60;json [   {     \&quot;type\&quot;: \&quot;tool_use\&quot;,     \&quot;id\&quot;: \&quot;toolu_01D7FLrfh4GYq7yT1ULFeyMV\&quot;,     \&quot;name\&quot;: \&quot;get_stock_price\&quot;,     \&quot;input\&quot;: { \&quot;ticker\&quot;: \&quot;^GSPC\&quot; }   } ] &#x60;&#x60;&#x60;  You might then run your &#x60;get_stock_price&#x60; tool with &#x60;{\&quot;ticker\&quot;: \&quot;^GSPC\&quot;}&#x60; as an input, and return the following back to the model in a subsequent &#x60;user&#x60; message:  &#x60;&#x60;&#x60;json [   {     \&quot;type\&quot;: \&quot;tool_result\&quot;,     \&quot;tool_use_id\&quot;: \&quot;toolu_01D7FLrfh4GYq7yT1ULFeyMV\&quot;,     \&quot;content\&quot;: \&quot;259.75 USD\&quot;   } ] &#x60;&#x60;&#x60;  Tools can be used for workflows that include running client-side tools and functions, or more generally whenever you want the model to produce a particular JSON structure of output.  See our [guide](https://docs.anthropic.com/en/docs/tool-use) for more details.
        /// </summary>
        /// <value>Definitions of tools that the model may use.  If you include &#x60;tools&#x60; in your API request, the model may return &#x60;tool_use&#x60; content blocks that represent the model&#39;s use of those tools. You can then run those tools using the tool input generated by the model and then optionally return results back to the model using &#x60;tool_result&#x60; content blocks.  Each tool definition includes:  * &#x60;name&#x60;: Name of the tool. * &#x60;description&#x60;: Optional, but strongly-recommended description of the tool. * &#x60;input_schema&#x60;: [JSON schema](https://json-schema.org/) for the tool &#x60;input&#x60; shape that the model will produce in &#x60;tool_use&#x60; output content blocks.  For example, if you defined &#x60;tools&#x60; as:  &#x60;&#x60;&#x60;json [   {     \&quot;name\&quot;: \&quot;get_stock_price\&quot;,     \&quot;description\&quot;: \&quot;Get the current stock price for a given ticker symbol.\&quot;,     \&quot;input_schema\&quot;: {       \&quot;type\&quot;: \&quot;object\&quot;,       \&quot;properties\&quot;: {         \&quot;ticker\&quot;: {           \&quot;type\&quot;: \&quot;string\&quot;,           \&quot;description\&quot;: \&quot;The stock ticker symbol, e.g. AAPL for Apple Inc.\&quot;         }       },       \&quot;required\&quot;: [\&quot;ticker\&quot;]     }   } ] &#x60;&#x60;&#x60;  And then asked the model \&quot;What&#39;s the S&amp;P 500 at today?\&quot;, the model might produce &#x60;tool_use&#x60; content blocks in the response like this:  &#x60;&#x60;&#x60;json [   {     \&quot;type\&quot;: \&quot;tool_use\&quot;,     \&quot;id\&quot;: \&quot;toolu_01D7FLrfh4GYq7yT1ULFeyMV\&quot;,     \&quot;name\&quot;: \&quot;get_stock_price\&quot;,     \&quot;input\&quot;: { \&quot;ticker\&quot;: \&quot;^GSPC\&quot; }   } ] &#x60;&#x60;&#x60;  You might then run your &#x60;get_stock_price&#x60; tool with &#x60;{\&quot;ticker\&quot;: \&quot;^GSPC\&quot;}&#x60; as an input, and return the following back to the model in a subsequent &#x60;user&#x60; message:  &#x60;&#x60;&#x60;json [   {     \&quot;type\&quot;: \&quot;tool_result\&quot;,     \&quot;tool_use_id\&quot;: \&quot;toolu_01D7FLrfh4GYq7yT1ULFeyMV\&quot;,     \&quot;content\&quot;: \&quot;259.75 USD\&quot;   } ] &#x60;&#x60;&#x60;  Tools can be used for workflows that include running client-side tools and functions, or more generally whenever you want the model to produce a particular JSON structure of output.  See our [guide](https://docs.anthropic.com/en/docs/tool-use) for more details.</value>
        [DataMember(Name="tools", EmitDefaultValue=false)]
        public List<BetaCountMessageTokensParamsToolsInner> Tools { get; set; }

        /// <summary>
        /// Only sample from the top K options for each subsequent token.  Used to remove \&quot;long tail\&quot; low probability responses. [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).  Recommended for advanced use cases only. You usually only need to use &#x60;temperature&#x60;.
        /// </summary>
        /// <value>Only sample from the top K options for each subsequent token.  Used to remove \&quot;long tail\&quot; low probability responses. [Learn more technical details here](https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277).  Recommended for advanced use cases only. You usually only need to use &#x60;temperature&#x60;.</value>
        [DataMember(Name="top_k", EmitDefaultValue=true)]
        public int? TopK { get; set; }

        /// <summary>
        /// Use nucleus sampling.  In nucleus sampling, we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified by &#x60;top_p&#x60;. You should either alter &#x60;temperature&#x60; or &#x60;top_p&#x60;, but not both.  Recommended for advanced use cases only. You usually only need to use &#x60;temperature&#x60;.
        /// </summary>
        /// <value>Use nucleus sampling.  In nucleus sampling, we compute the cumulative distribution over all the options for each subsequent token in decreasing probability order and cut it off once it reaches a particular probability specified by &#x60;top_p&#x60;. You should either alter &#x60;temperature&#x60; or &#x60;top_p&#x60;, but not both.  Recommended for advanced use cases only. You usually only need to use &#x60;temperature&#x60;.</value>
        [Range(0, 1)]
        [DataMember(Name="top_p", EmitDefaultValue=true)]
        public decimal? TopP { get; set; }

    }
}
