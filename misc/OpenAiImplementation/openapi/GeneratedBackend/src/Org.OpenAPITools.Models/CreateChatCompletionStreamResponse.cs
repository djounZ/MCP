/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

using System;
using System.Linq;
using System.Text;
using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Runtime.Serialization;
using System.Text.Json;
using Org.OpenAPITools.Converters;

namespace Org.OpenAPITools.Models
{ 
    /// <summary>
    /// Represents a streamed chunk of a chat completion response returned by the model, based on the provided input.  [Learn more](https://platform.openai.com/docs/guides/streaming-responses). 
    /// </summary>
    [DataContract]
    public partial class CreateChatCompletionStreamResponse 
    {
        /// <summary>
        /// A unique identifier for the chat completion. Each chunk has the same ID.
        /// </summary>
        /// <value>A unique identifier for the chat completion. Each chunk has the same ID.</value>
        [Required]
        [DataMember(Name="id", EmitDefaultValue=false)]
        public string Id { get; set; }

        /// <summary>
        /// A list of chat completion choices. Can contain more than one elements if &#x60;n&#x60; is greater than 1. Can also be empty for the last chunk if you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60;. 
        /// </summary>
        /// <value>A list of chat completion choices. Can contain more than one elements if &#x60;n&#x60; is greater than 1. Can also be empty for the last chunk if you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60;. </value>
        [Required]
        [DataMember(Name="choices", EmitDefaultValue=false)]
        public List<CreateChatCompletionStreamResponseChoicesInner> Choices { get; set; }

        /// <summary>
        /// The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.
        /// </summary>
        /// <value>The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp.</value>
        [Required]
        [DataMember(Name="created", EmitDefaultValue=true)]
        public int Created { get; set; }

        /// <summary>
        /// The model to generate the completion.
        /// </summary>
        /// <value>The model to generate the completion.</value>
        [Required]
        [DataMember(Name="model", EmitDefaultValue=false)]
        public string Model { get; set; }

        /// <summary>
        /// Gets or Sets ServiceTier
        /// </summary>
        [DataMember(Name="service_tier", EmitDefaultValue=true)]
        public ServiceTier ServiceTier { get; set; }

        /// <summary>
        /// This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the &#x60;seed&#x60; request parameter to understand when backend changes have been made that might impact determinism. 
        /// </summary>
        /// <value>This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the &#x60;seed&#x60; request parameter to understand when backend changes have been made that might impact determinism. </value>
        [DataMember(Name="system_fingerprint", EmitDefaultValue=false)]
        public string? SystemFingerprint { get; set; }


        /// <summary>
        /// The object type, which is always `chat.completion.chunk`.
        /// </summary>
        /// <value>The object type, which is always `chat.completion.chunk`.</value>
        
        public enum ObjectEnum
        {
            
            /// <summary>
            /// Enum ChatCompletionChunkEnum for chat.completion.chunk
            /// </summary>
            [EnumMember(Value = "chat.completion.chunk")]
            ChatCompletionChunkEnum = 1
        }

        /// <summary>
        /// The object type, which is always &#x60;chat.completion.chunk&#x60;.
        /// </summary>
        /// <value>The object type, which is always &#x60;chat.completion.chunk&#x60;.</value>
        [Required]
        [DataMember(Name="object", EmitDefaultValue=true)]
        public ObjectEnum Object { get; set; }

        /// <summary>
        /// An optional field that will only be present when you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60; in your request. When present, it contains a null value **except for the last chunk** which contains the token usage statistics for the entire request.  **NOTE:** If the stream is interrupted or cancelled, you may not receive the final usage chunk which contains the total token usage for the request. 
        /// </summary>
        /// <value>An optional field that will only be present when you set &#x60;stream_options: {\&quot;include_usage\&quot;: true}&#x60; in your request. When present, it contains a null value **except for the last chunk** which contains the token usage statistics for the entire request.  **NOTE:** If the stream is interrupted or cancelled, you may not receive the final usage chunk which contains the total token usage for the request. </value>
        [DataMember(Name="usage", EmitDefaultValue=false)]
        public CompletionUsage? Usage { get; set; }

    }
}
