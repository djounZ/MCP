/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

using System;
using System.Linq;
using System.Text;
using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Runtime.Serialization;
using System.Text.Json;
using Org.OpenAPITools.Converters;

namespace Org.OpenAPITools.Models
{ 
    /// <summary>
    /// Configuration for input audio transcription. The client can optionally set the language and prompt for transcription, these offer additional guidance to the transcription service. 
    /// </summary>
    [DataContract]
    public partial class RealtimeTranscriptionSessionCreateRequestInputAudioTranscription 
    {

        /// <summary>
        /// The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`. 
        /// </summary>
        /// <value>The model to use for transcription, current options are `gpt-4o-transcribe`, `gpt-4o-mini-transcribe`, and `whisper-1`. </value>
        
        public enum ModelEnum
        {
            
            /// <summary>
            /// Enum Gpt4oTranscribeEnum for gpt-4o-transcribe
            /// </summary>
            [EnumMember(Value = "gpt-4o-transcribe")]
            Gpt4oTranscribeEnum = 1,
            
            /// <summary>
            /// Enum Gpt4oMiniTranscribeEnum for gpt-4o-mini-transcribe
            /// </summary>
            [EnumMember(Value = "gpt-4o-mini-transcribe")]
            Gpt4oMiniTranscribeEnum = 2,
            
            /// <summary>
            /// Enum Whisper1Enum for whisper-1
            /// </summary>
            [EnumMember(Value = "whisper-1")]
            Whisper1Enum = 3
        }

        /// <summary>
        /// The model to use for transcription, current options are &#x60;gpt-4o-transcribe&#x60;, &#x60;gpt-4o-mini-transcribe&#x60;, and &#x60;whisper-1&#x60;. 
        /// </summary>
        /// <value>The model to use for transcription, current options are &#x60;gpt-4o-transcribe&#x60;, &#x60;gpt-4o-mini-transcribe&#x60;, and &#x60;whisper-1&#x60;. </value>
        [DataMember(Name="model", EmitDefaultValue=true)]
        public ModelEnum Model { get; set; }

        /// <summary>
        /// The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. &#x60;en&#x60;) format will improve accuracy and latency. 
        /// </summary>
        /// <value>The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) (e.g. &#x60;en&#x60;) format will improve accuracy and latency. </value>
        [DataMember(Name="language", EmitDefaultValue=false)]
        public string? Language { get; set; }

        /// <summary>
        /// An optional text to guide the model&#39;s style or continue a previous audio segment. For &#x60;whisper-1&#x60;, the [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting). For &#x60;gpt-4o-transcribe&#x60; models, the prompt is a free text string, for example \&quot;expect words related to technology\&quot;. 
        /// </summary>
        /// <value>An optional text to guide the model&#39;s style or continue a previous audio segment. For &#x60;whisper-1&#x60;, the [prompt is a list of keywords](https://platform.openai.com/docs/guides/speech-to-text#prompting). For &#x60;gpt-4o-transcribe&#x60; models, the prompt is a free text string, for example \&quot;expect words related to technology\&quot;. </value>
        [DataMember(Name="prompt", EmitDefaultValue=false)]
        public string? Prompt { get; set; }

    }
}
