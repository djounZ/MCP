/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * The version of the OpenAPI document: 2.3.0
 * 
 * Generated by: https://openapi-generator.tech
 */

using System;
using System.Linq;
using System.Text;
using System.Collections.Generic;
using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Runtime.Serialization;
using System.Text.Json;
using Org.OpenAPITools.Converters;

namespace Org.OpenAPITools.Models
{ 
    /// <summary>
    /// The aggregated completions usage details of the specific time bucket.
    /// </summary>
    [DataContract]
    public partial class UsageCompletionsResult 
    {

        /// <summary>
        /// Gets or Sets Object
        /// </summary>
        
        public enum ObjectEnum
        {
            
            /// <summary>
            /// Enum OrganizationUsageCompletionsResultEnum for organization.usage.completions.result
            /// </summary>
            [EnumMember(Value = "organization.usage.completions.result")]
            OrganizationUsageCompletionsResultEnum = 1
        }

        /// <summary>
        /// Gets or Sets Object
        /// </summary>
        [Required]
        [DataMember(Name="object", EmitDefaultValue=true)]
        public ObjectEnum Object { get; set; }

        /// <summary>
        /// The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.
        /// </summary>
        /// <value>The aggregated number of text input tokens used, including cached tokens. For customers subscribe to scale tier, this includes scale tier tokens.</value>
        [Required]
        [DataMember(Name="input_tokens", EmitDefaultValue=true)]
        public int InputTokens { get; set; }

        /// <summary>
        /// The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.
        /// </summary>
        /// <value>The aggregated number of text input tokens that has been cached from previous requests. For customers subscribe to scale tier, this includes scale tier tokens.</value>
        [DataMember(Name="input_cached_tokens", EmitDefaultValue=true)]
        public int? InputCachedTokens { get; set; }

        /// <summary>
        /// The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.
        /// </summary>
        /// <value>The aggregated number of text output tokens used. For customers subscribe to scale tier, this includes scale tier tokens.</value>
        [Required]
        [DataMember(Name="output_tokens", EmitDefaultValue=true)]
        public int OutputTokens { get; set; }

        /// <summary>
        /// The aggregated number of audio input tokens used, including cached tokens.
        /// </summary>
        /// <value>The aggregated number of audio input tokens used, including cached tokens.</value>
        [DataMember(Name="input_audio_tokens", EmitDefaultValue=true)]
        public int? InputAudioTokens { get; set; }

        /// <summary>
        /// The aggregated number of audio output tokens used.
        /// </summary>
        /// <value>The aggregated number of audio output tokens used.</value>
        [DataMember(Name="output_audio_tokens", EmitDefaultValue=true)]
        public int? OutputAudioTokens { get; set; }

        /// <summary>
        /// The count of requests made to the model.
        /// </summary>
        /// <value>The count of requests made to the model.</value>
        [Required]
        [DataMember(Name="num_model_requests", EmitDefaultValue=true)]
        public int NumModelRequests { get; set; }

        /// <summary>
        /// When &#x60;group_by&#x3D;project_id&#x60;, this field provides the project ID of the grouped usage result.
        /// </summary>
        /// <value>When &#x60;group_by&#x3D;project_id&#x60;, this field provides the project ID of the grouped usage result.</value>
        [DataMember(Name="project_id", EmitDefaultValue=false)]
        public string? ProjectId { get; set; }

        /// <summary>
        /// When &#x60;group_by&#x3D;user_id&#x60;, this field provides the user ID of the grouped usage result.
        /// </summary>
        /// <value>When &#x60;group_by&#x3D;user_id&#x60;, this field provides the user ID of the grouped usage result.</value>
        [DataMember(Name="user_id", EmitDefaultValue=false)]
        public string? UserId { get; set; }

        /// <summary>
        /// When &#x60;group_by&#x3D;api_key_id&#x60;, this field provides the API key ID of the grouped usage result.
        /// </summary>
        /// <value>When &#x60;group_by&#x3D;api_key_id&#x60;, this field provides the API key ID of the grouped usage result.</value>
        [DataMember(Name="api_key_id", EmitDefaultValue=false)]
        public string? ApiKeyId { get; set; }

        /// <summary>
        /// When &#x60;group_by&#x3D;model&#x60;, this field provides the model name of the grouped usage result.
        /// </summary>
        /// <value>When &#x60;group_by&#x3D;model&#x60;, this field provides the model name of the grouped usage result.</value>
        [DataMember(Name="model", EmitDefaultValue=false)]
        public string? Model { get; set; }

        /// <summary>
        /// When &#x60;group_by&#x3D;batch&#x60;, this field tells whether the grouped usage result is batch or not.
        /// </summary>
        /// <value>When &#x60;group_by&#x3D;batch&#x60;, this field tells whether the grouped usage result is batch or not.</value>
        [DataMember(Name="batch", EmitDefaultValue=true)]
        public bool? Batch { get; set; }

    }
}
